import streamlit as st
from openai import OpenAI
import datetime
import requests

# --- Î•Î¡Î•Î¥ÎÎ—Î¤Î™ÎšÎŸ Î Î•Î¡Î™Î’Î‘Î›Î›ÎŸÎ IRONBRICK ---
st.set_page_config(page_title="ironbrick Research IDE", layout="wide")

# Custom CSS
st.markdown("<style>header {visibility: hidden;} .stExpander { border: 2px solid #00a0dc; border-radius: 8px; }</style>", unsafe_allow_html=True)

# Î£ÏÎ½Î´ÎµÏƒÎ·
try:
    client = OpenAI(base_url="https://api.groq.com/openai/v1", api_key=st.secrets["GROQ_API_KEY"])
    DB_URL = st.secrets["GSHEET_URL"]
except:
    st.error("Connection Error: Check API Secrets.")

# --- RESEARCH LOGIC (ÎšÎ‘Î¤Î‘Î¤Î‘ÎÎ—) ---
MY_CODING_LOGIC = (
    "Analyze the student's prompt and categorize it: "
    "L1: Simple natural language, L2: Parameters/Values, L3: Logic/Loops, "
    "L4: Technical Terminology (Huskylens, RGB, etc), L5: Debugging. "
    "Return only the label (e.g., L1)."
)

# Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Session
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "last_output" not in st.session_state:
    st.session_state.last_output = ""

# Layout
tab_ide, tab_logs = st.tabs(["ğŸ’» IDE", "ğŸ“Š Data Access"])

with tab_ide:
    col1, col2 = st.columns([1, 1])
    
    with col1:
        if st.button("ğŸ—‘ï¸ ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î™ÏƒÏ„Î¿ÏÎ¹ÎºÎ¿Ï"):
            st.session_state.chat_history = []
            st.session_state.last_output = ""
            st.rerun()

        with st.form("input_form"):
            student_id = st.text_input("Student Code:", "S01")
            lang_choice = st.selectbox("Î“Î»ÏÏƒÏƒÎ± Î ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÏƒÎ¼Î¿Ï:", ["MicroPython", "Arduino C++"])
            mode = st.radio("Î¤ÏÏ€Î¿Ï‚ Î•Î½Î­ÏÎ³ÎµÎ¹Î±Ï‚:", ["ÎÎ­Î± Î£Ï…Î½Î¿Î¼Î¹Î»Î¯Î±", "Î”Î¹Î¿ÏÎ¸Ï‰ÏƒÎ· ÎµÎ½Ï„Î¿Î»Î®Ï‚"], horizontal=True)
            user_input = st.text_area("Î ÎµÏÎ¹Î³ÏÎ¬ÏˆÏ„Îµ Ï„Î·Î½ Î±Ï€Î¿ÏƒÏ„Î¿Î»Î® (Ï€.Ï‡. Maqueen, Huskylens, ÎºÏ„Î»):", height=150)
            btn = st.form_submit_button("Î•ÎºÏ„Î­Î»ÎµÏƒÎ·")

    with col2:
        if btn and user_input:
            if mode == "ÎÎ­Î± Î£Ï…Î½Î¿Î¼Î¹Î»Î¯Î±":
                st.session_state.chat_history = []
            
            st.session_state.chat_history.append({"role": "user", "content": user_input})
            
            with st.spinner('Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±...'):
                # 1. ÎšÎ±Ï„Î¬Ï„Î±Î¾Î· L1-L5
                analysis = client.chat.completions.create(
                    model="llama-3.3-70b-versatile",
                    messages=[{"role": "system", "content": MY_CODING_LOGIC}, {"role": "user", "content": user_input}]
                )
                current_level = analysis.choices[0].message.content.strip()

                # 2. Î Î±ÏÎ±Î³Ï‰Î³Î® ÎšÏÎ´Î¹ÎºÎ± (Î‘Ï…ÏƒÏ„Î·ÏÎ¬ Î³Î¹Î± micro:bit Maqueen)
                # Î•Î´Ï Î¿ÏÎ¯Î¶Î¿Ï…Î¼Îµ Ï„Î·Î½ ÎµÎ¹ÏƒÎ±Î³Ï‰Î³Î® Ï„Ï‰Î½ Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Ï‰Î½ Î²Î¹Î²Î»Î¹Î¿Î¸Î·ÎºÏÎ½ Î±Î½Î¬Î»Î¿Î³Î± Î¼Îµ Ï„Î· Î³Î»ÏÏƒÏƒÎ±
                maqueen_sys = (
                    f"You are a professional roboticist specializing in the micro:bit Maqueen. "
                    f"Generate strictly functional {lang_choice} code. "
                    "You MUST include all necessary imports/libraries at the top (e.g., from microbit import *, import maqueen, huskylens). "
                    "The code must be ready to run on the hardware. "
                    "Return ONLY the code. No markdown code blocks (```), no greetings, no comments."
                )
                
                messages = [{"role": "system", "content": maqueen_sys}] + st.session_state.chat_history
                code_res = client.chat.completions.create(model="llama-3.3-70b-versatile", messages=messages)
                final_code = code_res.choices[0].message.content.strip().replace("```python", "").replace("```cpp", "").replace("```", "")
                
                st.session_state.last_output = final_code
                st.markdown(f"**Î•ÏÎµÏ…Î½Î·Ï„Î¹ÎºÎ® ÎšÎ±Ï„Î¬Ï„Î±Î¾Î·: {current_level}**")
                st.code(final_code, language='python' if "Micro" in lang_choice else 'cpp')

                # 3. Logging
                log_entry = {
                    "data": [{
                        "Timestamp": str(datetime.datetime.now()),
                        "Student_ID": student_id,
                        "Action": mode,
                        "Coding_Level": current_level,
                        "Prompt": user_input,
                        "Code": final_code.replace('"', "'")
                    }]
                }
                requests.post(DB_URL, json=log_entry)

    # Î•Ï€ÎµÎ¾Î®Î³Î·ÏƒÎ· (Î‘Ï…ÏƒÏ„Î·ÏÎ¬ ÏƒÏ„Î± Î•Î»Î»Î·Î½Î¹ÎºÎ¬)
    if st.session_state.last_output:
        with st.expander("ğŸ’¡ Î Î±Î¹Î´Î±Î³Ï‰Î³Î¹ÎºÎ® Î•Ï€ÎµÎ¾Î®Î³Î·ÏƒÎ·"):
            exp_sys = (
                "Î•Î¯ÏƒÎ±Î¹ Î­Î¼Ï€ÎµÎ¹ÏÎ¿Ï‚ ÎºÎ±Î¸Î·Î³Î·Ï„Î®Ï‚ ÏÎ¿Î¼Ï€Î¿Ï„Î¹ÎºÎ®Ï‚. Î•Î¾Î®Î³Î·ÏƒÎµ Ï„Î· Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î± Ï„Î¿Ï… ÎºÏÎ´Î¹ÎºÎ± Maqueen "
                "Î±Ï€Î¿ÎºÎ»ÎµÎ¹ÏƒÏ„Î¹ÎºÎ¬ ÏƒÏ„Î± Î•Î»Î»Î·Î½Î¹ÎºÎ¬. Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¯Î·ÏƒÎµ Î±Ï€Î»Î® Î³Î»ÏÏƒÏƒÎ±, ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î· Î³Î¹Î± Î¼Î±Î¸Î·Ï„Î­Ï‚ Ï€Î¿Ï… "
                "ÎºÎ¬Î½Î¿Ï…Î½ Ï„Î· Î¼ÎµÏ„Î¬Î²Î±ÏƒÎ· Î±Ï€ÏŒ Ï„Î± Blocks ÏƒÏ„Î¿Î½ ÎºÏÎ´Î¹ÎºÎ±."
            )
            explanation = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "system", "content": exp_sys}, {"role": "user", "content": st.session_state.last_output}]
            )
            st.write(explanation.choices[0].message.content)
