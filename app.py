import streamlit as st
from openai import OpenAI
import datetime

# 1. Î¡ÏÎ¸Î¼Î¹ÏƒÎ· Î£ÎµÎ»Î¯Î´Î±Ï‚
st.set_page_config(page_title="Maqueen Robotics Lab", page_icon="ğŸ¤–", layout="wide")

# 2. Î£ÏÎ½Î´ÎµÏƒÎ· Î¼Îµ Ï„Î¿ API Ï„Î·Ï‚ Groq
try:
    api_key_secret = st.secrets["GROQ_API_KEY"]
    client = OpenAI(
        base_url="https://api.groq.com/openai/v1",
        api_key=api_key_secret
    )
except Exception as e:
    st.error("âŒ Î¤Î¿ API Key (GROQ_API_KEY) Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ ÏƒÏ„Î± Secrets!")
    st.stop()

# 3. Sidebar - Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Admin
st.sidebar.title("âš™ï¸ Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Admin")
if st.sidebar.checkbox("Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î•Ï€Î¹Î»Î¿Î³ÏÎ½ ÎšÎ±Ï„ÎµÎ²Î¬ÏƒÎ¼Î±Ï„Î¿Ï‚"):
    try:
        with open("research_logs.txt", "r", encoding="utf-8") as f:
            st.sidebar.download_button(
                label="ğŸ“¥ ÎšÎ±Ï„Î­Î²Î±ÏƒÎ¼Î± Logs (TXT)",
                data=f,
                file_name=f"robotics_logs_{datetime.date.today()}.txt",
                mime="text/plain"
            )
    except FileNotFoundError:
        st.sidebar.warning("Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ Î±ÎºÏŒÎ¼Î± ÎºÎ±Ï„Î±Î³ÏÎ±Ï†Î­Ï‚.")

# 4. Î ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½ ÎœÎ±Î¸Î·Ï„Î®
st.title("ğŸ¤– Maqueen Micro:bit AI Assistant")
st.info("Î ÎµÏÎ¯Î³ÏÎ±ÏˆÎµ Ï„Î¹ Î¸Î­Î»ÎµÎ¹Ï‚ Î½Î± ÎºÎ¬Î½ÎµÎ¹ Ï„Î¿ ÏÎ¿Î¼Ï€ÏŒÏ„ Maqueen ÎºÎ±Î¹ Ï€Î¬ÏÎµ Ï„Î¿Î½ ÎºÏÎ´Î¹ÎºÎ± ÏƒÎµ Python!")

student_id = st.text_input("ID ÎœÎ±Î¸Î·Ï„Î®:", "Guest")
user_prompt = st.text_area("Î ÎµÏÎ¯Î³ÏÎ±ÏˆÎµ Ï„Î·Î½ Î±Ï€Î¿ÏƒÏ„Î¿Î»Î® (Ï€.Ï‡. 'Î‘Ï€Î¿Ï†Ï…Î³Î® ÎµÎ¼Ï€Î¿Î´Î¯Ï‰Î½'):")

# 5. Î•ÎºÏ„Î­Î»ÎµÏƒÎ·
if st.button("ğŸš€ Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎšÏÎ´Î¹ÎºÎ± & ÎšÎ±Ï„Î±Î³ÏÎ±Ï†Î®"):
    if user_prompt:
        with st.spinner('â³ Î¤Î¿ AI Î´Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Ï„Î¿Î½ ÎºÏÎ´Î¹ÎºÎ±...'):
            try:
                response = client.chat.completions.create(
                    model="llama-3.3-70b-versatile",
                    messages=[
                        {
                            "role": "system", 
                            "content": "Î•Î¯ÏƒÎ±Î¹ ÎµÎ¹Î´Î¹ÎºÏŒÏ‚ ÎºÎ±Î¸Î·Î³Î·Ï„Î®Ï‚ Maqueen. Î‘Ï€Î±Î½Ï„Î¬Ï‚ ÏƒÏ„Î± Î•Î»Î»Î·Î½Î¹ÎºÎ¬ ÎºÎ±Î¹ Î´Î¯Î½ÎµÎ¹Ï‚ Ï€Î¬Î½Ï„Î± Î¿Î»ÏŒÎºÎ»Î·ÏÎ¿ Ï„Î¿Î½ ÎºÏÎ´Î¹ÎºÎ± MicroPython."
                        },
                        {"role": "user", "content": user_prompt}
                    ]
                )
                
                answer = response.choices[0].message.content
                st.subheader("ğŸ“ ÎŸ ÎšÏÎ´Î¹ÎºÎ±Ï‚ ÏƒÎ¿Ï…:")
                st.markdown(answer)
                
                # 6. Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· ÎŸÎ›ÎŸÎšÎ›Î—Î¡Î—Î£ Ï„Î·Ï‚ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·Ï‚ (Î”Î¹Î¿ÏÎ¸Ï‰Î¼Î­Î½Î¿ Syntax)
                try:
                    with open("research_logs.txt", "a", encoding="utf-8") as f:
                        ts = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        f.write(f"TS: {ts} | ID: {student_id}\n")
                        f.write(f"PROMPT: {user_prompt}\n")
