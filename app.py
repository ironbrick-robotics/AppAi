import streamlit as st
from openai import OpenAI
import datetime
import requests

# --- Î•Î¡Î•Î¥ÎÎ—Î¤Î™ÎšÎŸ Î Î•Î¡Î™Î’Î‘Î›Î›ÎŸÎ IRONBRICK ---
# Î¥Î»Î¿Ï€Î¿Î¯Î·ÏƒÎ·: [Î¤Î¿ ÎŸÎ½Î¿Î¼Î±Ï„ÎµÏ€ÏÎ½Ï…Î¼ÏŒ Î£Î¿Ï…]
# Î£ÎºÎ¿Ï€ÏŒÏ‚: ÎœÎµÎ»Î­Ï„Î· Î¼ÎµÏ„Î¬Î²Î±ÏƒÎ·Ï‚ Î±Ï€ÏŒ Blocks ÏƒÎµ Text-based Code

st.set_page_config(page_title="ironbrick Research IDE", layout="wide")

# Custom CSS Î³Î¹Î± Ï„Î¿ interface Ï„Î·Ï‚ Î­ÏÎµÏ…Î½Î±Ï‚
st.markdown("""
    <style>
    header {visibility: hidden;}
    .stExpander { border: 2px solid #00a0dc; border-radius: 8px; }
    </style>
    """, unsafe_allow_html=True)

# Î£ÏÎ½Î´ÎµÏƒÎ· Î¼Îµ Ï„Î± API (Secrets)
try:
    client = OpenAI(base_url="https://api.groq.com/openai/v1", api_key=st.secrets["GROQ_API_KEY"])
    DB_URL = st.secrets["GSHEET_URL"]
except:
    st.error("Connection Error: Check API Configuration.")

# ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ Ï„Î¿Ï… Î´Î¹ÎºÎ¿Ï ÏƒÎ¿Ï… Coding Scheme Î³Î¹Î± Ï„Î·Î½ Î±Î½Î¬Î»Ï…ÏƒÎ·
MY_CODING_LOGIC = (
    "Analyze the student's prompt and categorize it into the following levels: "
    "L1: Simple natural language, L2: Parameters/Values, L3: Logic/Loops, "
    "L4: Technical Terminology, L5: Debugging/Iteration. "
    "Return only the label (e.g., L3)."
)

# ÎšÏÏÎ¹Î¿ Interface
tab_ide, tab_logs = st.tabs(["ğŸ’» IDE", "ğŸ“Š Data Access"])

with tab_ide:
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        with st.form("input_form"):
            student_id = st.text_input("Student Code:", "S01")
            mode = st.selectbox("Task Type:", ["New Mission", "Correction"])
            user_input = st.text_area("Î ÎµÏÎ¹Î³ÏÎ¬ÏˆÏ„Îµ Ï„Î·Î½ Î±Ï€Î¿ÏƒÏ„Î¿Î»Î®:", height=150)
            btn = st.form_submit_button("Generate Code")

    with col2:
        if btn and user_input:
            st.session_state.chat_history.append({"role": "user", "content": user_input})
            
            # 1. Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î· ÎšÏ‰Î´Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· (Research Metric)
            analysis = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "system", "content": MY_CODING_LOGIC}, {"role": "user", "content": user_input}]
            )
            current_level = analysis.choices[0].message.content.strip()

            # 2. Î Î±ÏÎ±Î³Ï‰Î³Î® ÎšÏÎ´Î¹ÎºÎ± Maqueen
            maqueen_prompt = "Expert Maqueen coder. Clean code only, no explanations, no markdown blocks."
            messages = [{"role": "system", "content": maqueen_prompt}] + st.session_state.chat_history
            code_res = client.chat.completions.create(model="llama-3.3-70b-versatile", messages=messages)
            final_code = code_res.choices[0].message.content.strip()
            
            st.session_state.last_output = final_code
            st.code(final_code, language='python')

            # 3. Î‘Ï…Ï„ÏŒÎ¼Î±Ï„Î¿ Logging ÏƒÏ„Î¿ Google Sheet
            log_data = {
                "data": [{
                    "Timestamp": str(datetime.datetime.now()),
                    "Student_ID": student_id,
                    "Action": mode,
                    "Coding_Level": current_level,
                    "Prompt": user_input,
                    "Code": final_code
                }]
            }
            requests.post(DB_URL, json=log_data)
            st.toast(f"Logged as {current_level}")

    # Î Î±Î¹Î´Î±Î³Ï‰Î³Î¹ÎºÎ® Î‘Î½Î±Ï„ÏÎ¿Ï†Î¿Î´ÏŒÏ„Î·ÏƒÎ·
    if "last_output" in st.session_state:
        with st.expander("ğŸ’¡ Î•Ï€ÎµÎ¾Î®Î³Î·ÏƒÎ· ÎšÏÎ´Î¹ÎºÎ± Î³Î¹Î± Ï„Î¿Î½ ÎœÎ±Î¸Î·Ï„Î®"):
            pedagogical_prompt = "Î•Î¯ÏƒÎ±Î¹ ÎºÎ±Î¸Î·Î³Î·Ï„Î®Ï‚ ÏÎ¿Î¼Ï€Î¿Ï„Î¹ÎºÎ®Ï‚. Î•Î¾Î®Î³Î·ÏƒÎµ Ï„Î¿Î½ ÎºÏÎ´Î¹ÎºÎ± ÏƒÏ„Î± Î•Î»Î»Î·Î½Î¹ÎºÎ¬ Î¼Îµ Î±Ï€Î»Î¬ Î»ÏŒÎ³Î¹Î±."
            explanation = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "system", "content": pedagogical_prompt}, {"role": "user", "content": st.session_state.last_output}]
            )
            st.write(explanation.choices[0].message.content)
